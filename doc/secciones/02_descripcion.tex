\chapter{Descripción del problema}

 WIP--
The soccer analytics community is growing year after year. The potential 
of soccer data is not only catching the attention of researchers and 
amateur analysts but is also attracting more and more interest from 
soccer clubs. While the increased availability of freely available 
data and tools as well as the global pandemic led to an explosion of 
soccer analytics content in 2020, soccer clubs have arguably made a 
record-number of signings for data-related roles in 2021. Nevertheless, 
a significant number of high-quality blog posts and research papers has 
appeared in the past year. 

Este proyecto tiene como idea ayudar desde los jugadores hasta 
el cuerpo técnico del equipo: entrenadores, director técnico, preparadores 
físicos y analistas tácticos,también conocidos como 'scouting'.
-- WIP 

What is analytics good for?
Contribution
Style
Skill
Potential
Big questions

Contribution is the most straightforward, since it’s about measuring who 
did what (although when you try to put a value on those contributions 
things get more complicated). 

Style separates what happened from how and why.

Skill, at the player level, tries to give a more nuanced-and 
speculative-picture of contribution by accounting for circumstances 
like role, tactics, and team strength. 

Potential strays even further from what we know into what we wish we 
knew, trying to project how a team or player or even a particular 
pattern of play would fare under circumstances different from in the 
past, like how a young player might grow if he transferred to a team 
with an unfamiliar playstyle in a tougher league. And then there’s 
a catchall for research questions that sprawl across or outside 
the other categories. This might include evaluations of a game 
model or of specific tactics.

You can do all of this without data—they’re really just kinds 
of questions you can ask about soccer, not inherently quantitative 
problems—and a lot of coaches and sporting directors would rather 
trust analysts’ eyes than whatever some computer spits out. But 
the supposed dichotomy between data and video, or data and scouting, 
or data and knowing anything at all about the game, is transparently 
phony. Good analytics are always informed by what the nerds call 
“domain knowledge”—the expertise of players and staff. If you do it 
right, you might even get some benefits flowing the other direction, too. 
The best analytics work makes us better at seeing and thinking about the game.

Most clubs do at least some data scouting. The generally accepted best 
practice is you use stats to pull together a list of some good prospects 
who fit the profile you’re looking for, doing a much wider and faster 
first pass than a scouting network could; then you watch a bunch of video 
to get a more complete picture of the players and narrow things down; 
and finally you might send out a scout to get to know your favorite 
guys in their environments and maybe watch a few live games just for 
kicks. Done right, this can make the recruiting process more efficient 
and with any luck find you better players for cheaper than the old 
system of binoculars in the stands and agents hawking their guys 
on the phone. 

And then there are what you might call the big questions. Billy Beane’s 
staff was focused on buying cheap wins, but they took their inspiration 
from Bill James, an idealistic fan prone to writing things like, 
“I do not start with the numbers any more than a mechanic starts with 
a monkey wrench. I start with the game, with the things that I see 
there and the things that people say there. And I ask: Is it true? 
Can you validate it? Can you measure it? How does it fit with the 
rest of the machinery?”

The best possible use of analytics isn’t just to measure the game 
but to understand it. That’s what smart clubs do when they use data 
to ask questions about how they play, or better yet how they should 
play. It’s what academic researchers and curious fans do with whatever 
data they can get their hands on. It’s what Charles Reep and Herbert 
Chapman and those Hungarian newspaper readers were after, even if it 
didn’t always work out.

\section{Tipos de análisis en el fútbol de alto rendimiento}

\subsection{Análisis estadístico}
Consiste en obtener y acumular datos de jugadores o equipos 
en entrenamientos y partidos para fines estadísticos.

Estos datos nos ayudarán pues a tener información sobre aspectos condicionales 
útiles para, entre otros:

\begin{itemize}
    \item La prevención de lesiones
    \item Efectividad de los jugadores en diferentes acciones de partido
    \item Análisis cuantitativo del origen de situaciones de peligro en 
    fase ofensiva o defensiva
\end{itemize}

A través de estos datos se realizarán unos informes para después sacar las 
conclusiones oportunas. Del material necesario, podemos destacar:

\begin{itemize}
    \item Cámaras de vídeo
    \item Pulsómetros
    \item "Trackers" de movimiento
    \item Programas estadísticos
\end{itemize}

\subsection{Análisis del equipo rival}

Para ello se utilizan plataformas para descarga de partidos en alta 
calidad como Wyscout, programas de edición y análisis de video como 
Longomatch, y plantillas de informes para organizar la información recogida.

Es importante conocer al rival en su contexto y hacer un poco de investigación antes 
de ponerte a observar partidos, ya que esto nos permitirá entender 
mejor todo lo que vamos viendo.

\subsection{Análisis del equipo o jugadores propios}
Puede focalizarse en alguno de los siguientes 3 aspectos:

\begin{itemize}
    \item Los jugadores
    \item Las líneas
    \item El conjunto del equipo
\end{itemize}

El objetivo es mejorar o potenciar aquellos aspectos que creamos necesarios 
a través de:

\begin{itemize}
    \item La concienciación de la situación
    \item La identificación del problema, si lo hay
    \item La solución óptima que nos permita tener éxito en esa situación
\end{itemize}

Este trabajo normalmente se realiza antes y después de los partidos y 
ayuda muchísimo a la planificación del día a día y de los contenidos 
de entrenamiento que se van a realizar, ya sea para mejorar, potenciar 
o eliminar conductas en el juego.

\subsection{Análisis en directo}
Es tanto o más importante que el estudio que se hace del rival antes 
del partido.

Muchas veces lo que hemos planteado o lo que creemos que va a pasar no 
es lo que ocurre, y por ese motivo es vital ajustar detalles durante 
el partido para aumentar las posibilidades de victoria. El entrenador, 
durante el partido, no se encuentra con una perspectiva del campo 
idónea para identificar organizaciones espaciales, comportamientos 
de equipo propio y rival, actuación de jugadores lejanos al centro 
de juego, etc. Todo esto, sumado a la tensión del entrenador durante 
los partidos, propicia que se escapen detalles relevantes.

Por este motivo, los scouts trabajan normalmente durante el partido analizando 
in situ, con la ayuda de un par de cámaras, lo que está 
ocurriendo. Usualmente también lo que se hace es elaborar un informe 
que se hace llegar al entrenador al descanso y que le puede ser 
de mucha ayuda.


\subsection{Análisis de jugadores para contratación}

Por último, una de las tareas de los scouts es captar jugadores. 
Para ello, será imprescindible conocer el perfil de jugador que 
se necesita, detallando cada una de las estructuras de juego:

\begin{itemize}
    \item Coordinativa
    \item Condicional
    \item Cognitiva
    \item Socio-afectiva
\end{itemize}

El analista deberá hacer una revisión en profundidad y al detalle de 
todos los aspectos que desencadenan de cada una de las estructuras. 
Cuanto más detallado sea el análisis, más probabilidad de acertar 
en el perfil de jugador necesario y por lo tanto de tener éxito.

\section{Perfiles dentro del análisis de fútbol}
De manera general y sencilla, podemos decir que el scouting es el proceso de 
recogida de información para su posterior análisis.

\subsection{¿Cuál es la diferencia entre Scouter, Scout, Analista y Ojeador?}
Aunque aparentemente todos parecen casi lo mismo, cada uno tiene una 
identidad propia muy diferenciada. \textbf{Scout} es el término ingles de la 
persona encargada de hacer scouting, pero históricamente desde su 
origen, el término tiene grandes connotaciones orientada a captación 
de talento. Sin embargo, el analista es un perfil más enfocado al 
rendimiento deportivo de los equipos. Por lo tanto, los scouts están 
más metidos en las secretarias técnicas, mientras que el analista 
se involucra más con el cuerpo técnico.

El \textbf{scouter u ojeador} es la persona que observa los partidos de 
fútbol con el objetivo de identificar talento, ya sea jugadores 
jóvenes o no, que puedan ser incorporados al equipo. Antiguamente 
era más común visualizar presencialmente los partidos, pero 
actualmente se combina el uso de herramientas como InStat 
con asistir a partidos en directo.

Es muy común que el scouter esté constantemente viajando, o incluso 
desplazado en otra área geográfica, sin casi relación directa 
con el equipo, aunque evidentemente tiene que conocerlo a la 
perfección, ya que los posibles fichajes tienen que ir en 
sintonía con el modelo de juego. Podría darse incluso que fuera 
una persona ajena al club, freelance o perteneciente a una empresa, 
pero ligada al mundo del fútbol.

Tiene que tener un talento especial y una capacidad para poder 
predecir la futura adaptación y evolución de un jugador dentro 
de tu club. Además, por momentos requiere una gran capacidad de 
concentración observando solamente un determinado jugador, 
olvidándose de la potencia de atracción que tiene el balón. 
Es tan importante conocer cómo se comparta un jugador sin 
balón como con él.

En España, Sevilla FC y  Villarreal CF son los clubes con más 
scouters repartidos por los diferentes territorios. Sevilla por ejemplo
cuenta con más de 700. Se nota en ambos su capacidad de fichajes 
y captación de talento al fútbol base. En el extranjero, por 
ejemplo el Bayer Leverkusen cuenta con 50 scouters a tiempo parcial 
y 15 a tiempo completo.

El \textbf{analista} del juego es más un encargado de estudiar el 
fútbol en cada una de sus fases, desglosándolo e identificando 
de manera pormenorizada las características y patrones en los 
equipos. A diferencia del scouter, es un rol más orientado 
en el rendimiento grupal y su análisis, y más involucrado 
en el día a día del equipo, cuerpo técnico y jugadores.

Por su capacidad de conocer las fortalezas y debilidades de 
los equipos, está fuertemente ligado al entrenador en el 
día a día, para aportar su granito de arena en la estrategia 
operativa. Viaja con el equipo, asiste a los entrenamientos 
y es parte activa de la toma de decisiones del cuerpo técnico.

El analista se centra más en lo táctico, aunque cada vez hay 
más diferenciaciones dentro del analista:

\begin{itemize}
    \item Analista táctico: especializados en las fases del juego y acciones 
    a balón parado.
    \item Analista técnico: centrados en mejorar los movimientos y acciones 
    técnicas individuales, más orientados al fútbol base.
    \item Analista de rendimiento físico: normalmente preparadores físicos 
    que siguen metodologías de análisis haciendo uso de datos 
    proporcionados por GPS o sistemas similares.
    \item Analista de datos: especialista en la captura, tratamiento e 
    interpretación de los mismos.
\end{itemize}

\section{Métricas en el fútbol moderno: concepto, análisis y uso}
Con la incorporación progresiva del Big Data en el fútbol, 
los marcadores de rendimiento tradicionales se han visto 
abrumados por la cantidad de registros e información que 
se recogen con las nuevas metodologías de trabajo: GPS, drones, 
métricas, modelos predictivos,...

Esto no aplica solo al aspecto físico, donde a nivel profesional, 
es impensable que un equipo no trabaje con este tipo de dispositivos, 
o no tenga en cuenta dentro de los entrenamientos datos como el 
número de aceleraciones, deceleraciones o la distancia a sprint 
en diferentes rangos de velocidad que realizan los jugadores.

El aspecto técnico-táctico también se ha visto influenciado y 
ahora podemos conocer el número de contactos de un jugador con 
el balón, el porcentaje de acierto, la dirección, el número de 
ataques realizado por sector del campo e incluso construir 
redes donde se vislumbre las conexiones entre jugadores, y 
estos avances incluyen las métricas, esto es, combinaciones de datos 
que nos sirven para analizar el rendimiento.

\subsection{Expected goals o Goles esperados, xG}
La métrica xG se basa en la atribución a una ocasión creada de 
un valor entre 0 a 1, siendo este valor dependiente de diversos 
factores, e interpretable como un porcentaje de conseguir dicho gol. 
Por ejemplo a un valor 0,1 le correspondería un 10\% de posibilidades 
de conseguir marcar. Normalmente, se suele utilizar los tiros 
como sustitutos para contabilizar las oportunidades de gol, 
ya que son intentos de anotar y son sencillos de identificar, 
y se utiliza la distancia y ángulo como variables principales.

Dependiendo del distribuidor de los datos, se tienen en cuenta una 
serie de diferentes variables- tipo de asistencia, ángulo de tiro y 
distancia a la portería entre ellos- y el modelo entrenado para 
facilitar los datos suele variar.

Los goles esperados sirven entonces para determinar 
los goles que se esperaría que un equipo marcase a partir de 
la cantidad y la calidad de las ocasiones de gol creadas en un 
partido. Es, posiblemente, la métrica avanzada más prominente 
usada hoy en día en el fútbol y también se puede utilizar para 
evaluar estadísticamente a los jugadores.

Además esta métrica, de forma general, contiene más información 
del verdadero rendimiento del equipo en el campo que los 
resultados del partido.

\subsection{Expected assists o Asistencias esperadas, xA}
Las asistencias esperadas miden la probabilidad de que un pase se 
convierta en una asistencia de gol. Para ello, similar al caso de xG, 
se le asigna un valor al pase que se relaciona con la oportunidad 
de que acabe siendo una asistencia. Pese a ser similar al xG, el 
valor que se le asigna no depende de si finalmente el compañero 
realiza un tiro a portería. Para obtenerlo, se consideran factores 
como el tipo de pase, la distancia y la posición donde recibe la 
pelota el compañero.

\subsection{Expected points o Puntos esperados,xP o xPts}
Los puntos esperados es una métrica que refleja la cantidad 
promedio de puntos a largo plazo que un equipo habría 
esperado conseguir si el partido se hubiese jugado cientos de miles de veces.

Se calcula partiendo de los xG acumulados en un partido, comparando 
los conseguidos por ambos equipos. Posteriormente se simula 
el partido con todas las probabilidades de los tiros un número 
muy elevado de veces,por ejemplo: 100.000, y se anota las veces 
que gana un equipo, las veces que pierde o las veces que 
se produce un empate.

El número conseguido en cada apartado se pasa a porcentaje, 
y se aplica la siguiente fórmula:

xP = Puntos que se consiguen por ganar x Posibilidad de ganar + 
     Puntos que se consiguen por empatar x Posibilidad de empatar + 
     Puntos que se consiguen por perder x Posibilidad de perder.

Los equipos dominantes suelen presentar entre 2.1-2.8 xP, mientras 
que los dominados rozan los 0.1-0.5 xP. 

\subsection{Pases Permitidos por Acción Defensiva,PPDA}
Esta métrica busca determinar la presión que realizó el 
equipo defensor sobre los jugadores rivales cuando 
tienen la pelota. Para ello se tienen en cuenta el número 
de pases realizados por el equipo atacante y el número de 
acciones defensivas: entradas, intercepciones, faltas y duelos 
defensivos ganados, que se producen en 60\% del campo del 
equipo defensor.

\section{Metodología}

Desarrollo ágil
Planteamiento
Con el término desarrollo ágil se agrupan una serie de buenas prácticas en 
el sector de la informática que ayudan a conseguir productos de calidad, 
adaptados a las necesidades de los clientes, y flexibles. 

Hace ahora 20 años, el manifiesto ágil apostaba por una nueva manera de 
entender el desarrollo de software que aportara valor al cliente y que fuera 
ágil en la evolución del mismo, a la vez que proporcionara un entorno de 
trabajo más satisfactorio para quien lo desarrolla.

Este manifiesto tenía una serie de lemas, que en general se presentaban en 
contraposición al método de cascada o waterfall en el que las diferentes 
fases de desarrollo estaban aisladas y diferenciadas, y sólo se pasaba a 
producción al final de una larga cadena de departamentos aislados entre sí. 
Los principales lemas eran:
\begin{itemize}
    \item Menos documentación, y más código funcionando. La documentación excesiva en 
    forma de contratos y especificaciones funcionales no sirve de nada si no se 
    acompaña de código que funcione; el código funcionando es la mejor forma de 
    asegurar que efectivamente se entienden correctamente los requisitos del 
    cliente.
    \item Menos procesos, más interacción con el cliente y de los 
    programadores entre sí. En vez de compartimentos aislados, con una 
    cascada y el cliente en ambos extremos, las interacciones del cliente 
    deben ser constantes, y los diferentes grupos de programadores llevando 
    a cabo ese programa interaccionan continuamente para llevar el código a 
    un estado en el que se pueda mostrar al cliente.
    \item La colaboración del cliente no debe ser exclusivamente mediante 
    contratos, sino mediante una interacción continua donde se le 
    muestre productos funcionando y el cliente vea si eso corresponde a sus 
    expectativas o no; si no lo hace, debe de organizarse el equipo de forma 
    ágil para evolucionar el producto hasta que lo haga.
\end{itemize}

Estos lemas se organizan en una serie de principios, doce en total, de los cuales destacamos:

\begin{itemize}
    \item 

La programación tiene que centrarse en resolver problemas. 
Lo más importante es eso, y debe ser el principal enfoque 
de la tarea. Resolverlos, y tener métodos ágiles para comprobar 
que efectivamente se ha resuelto.
Para interaccionar con el cliente y que vea esos productos 
mínimamente viables, hay que publicar frecuentemente, 
pasando a producción cualquier cosa que esté lista y 
pase todos los tests. En este sentido, se parece al 
release early, release often del mundo del software libre.
El diseño es esencial, aunque dentro de los límites de 
que se prefiere el código a la documentación. El diseño 
previo a la codificación debe seguir todos los lemas y 
todos los principios ágiles.
Hay que atenerse a las buenas prácticas para codificar, 
en todas las áreas del proyecto, desde cómo nombrar 
las variables hasta que’tipo de herramientas y metodologías 
se consideran las mejores en un momento determinado. 
Es decir, cuando se comience un proyecto debe de 
dedicarse cierto tiempo a establecer cuales son 
esas buenas prácticas. En la evolución del mismo, 
será esencial para su flexibilidad y comprensibilidad seguir las mismas.
La simplicidad es esencial, y no se debe hacer más 
que lo que hay en los requisitos, ni buscar más 
características que las que estrictamente se necesiten 
para resolver un problema.
El trabajo se debe revisar frecuentemente, con el objetivo 
de hacerlo más eficiente, adaptarlo a nuevos requisitos, 
o simplemente incorporarlo a producción; el código siempre 
debe haber pasado por varios ojos antes de que sea hábil para funcionar.
Estos principios deben guiar una metodología de trabajo. 
Para empezar, dice que hay que empezar por un problema a 
resolver, no con qué se quiere hacer. Las soluciones no 
pueden estar por delante del problema. Es decir, empezar 
por decir las herramientas que se van a usar para hacer 
algo es una forma de empezar algo que no va a ser simple, 
posiblemente no resuelva ningún problema, y sea difícil 
de probar si efectivamente funciona o no. Además, te 
indica que hay que organizar el trabajo en hitos, 
cada uno de los cuales implicará la publicación de 
un producto mínimamente viable, cada uno de los 
cuales se construirá sobre el anterior o se agregará 
al anterior, según el problema. Sin un producto 
mínimamente viable, no se puede testear, y sin tener 
claro qué problema se quiere resolver, tampoco.

La calidad en el software empieza por el diseño, y este 
diseño incluye desde la modularización del problema, 
hasta el el uso de lenguaje, bibliotecas o estructuras 
de datos para trabajar. En informática rara vez hay 
una sola forma de hacer las cosas, y siempre hay que 
tomar decisiones técnicas que tendrán implicaciones 
en la evolución del software. Diseñar te va ayudar 
a escribir menos código, y el mejor código es el 
que no hay que testear, con lo que será código de 
más claridad. Un diseño flexible, por capas, que 
desacople diferentes partes del mismo, será también 
mucho más fácil de adaptar a diferentes circunstancias.

Y la búsqueda de mejores prácticas es esencial. La 
sintaxis y los manuales de referencia, y los tutoriales, 
rara vez se preocupan de guiar en la toma de una serie 
de decisiones técnicas. Te presentan una solución como 
ideal, o posiblemente la única posible. Sin embargo, 
llegar a esas soluciones implica una serie de decisiones, 
y es en las que hay que seguir las mejores prácticas, 
a todos los niveles: personales, empresas, industria.

Finalmente, se tiene que establecer una infraestructura 
para revisión de código. Lo más simple es establecer 
un estándar en el cual no se incorpore código a la 
rama principal directamente, sino que se haga 
siempre mediante pull requests. Pero adicionalmente, 
el desarrollo ágil pide la creación de una serie de 
reuniones, normalmente llamadas retro, que revisan 
el código que ha puesto en producción, y sugiere, 
siempre de forma constructiva, diferentes mejoras, que 
se incorporarán a un MVP futuro. El pasar tests 
frecuentemente para guardarse de posibles cambios 
en las dependencias también es una buena práctica, 
porque cerrarse en una versión determinada de todo 
puede ser eficiente a la hora de llevar a producción, 
pero las versiones de todo acaban siendo deprecadas y
no quieres encontrarte en una situación en la cual 
tengas que reescribir todo por usar algo con posibles huecos de seguridad.

\end{itemize}

Capturando los deseos de los clientes
Los deseos de los clientes se capturarán en unas historias de usuario. 
Pero previo a las historias de usuario se tendrán que crear unas 
narrativas de los diferentes pasos que van a dar los diferentes 
tipos de usuario, una visión más global que, más adelante, se 
dividirá en fragmentos, historias de usuario, testeables y 
programables. Estas narrativas se llaman épicas. En general, 
como afirma en el enlace anterior:

Son historias de usuario demasiado extensas que se tienen 
que dividir en otras más pequeñas.

Y en este punto es donde es conveniente empezar a usar las 
mejores prácticas en el desarrollo ágil. Hay muchas formas 
de llevarlo a cabo, pero generalmente se agrupan en dos 
campos diferentes: los partidarios de usar scrum o los 
usuarios de kanban. Hay diferencias considerables, aunque 
los dos coinciden en el hecho de que se trabaje sistemáticamente 
con historias de usuario… y con un tablero. Los tableros permiten 
ver claramente en qué estado está el trabajo, y permite organizar 
las historias de usuario en diferentes columnas según el estado 
en el que estén. Las columnas clásicas son “Por hacer”, 
“haciéndose” y “hecho”, pero se pueden añadir otras columnas 
según el proyecto y el equipo: Diseño técnico, o Tormenta 
de Ideas. Estas últimas permiten interaccionar, a través 
de la herramienta que se elija. Por simplicidad, es 
mejor que sea la que provee el gestor de código, por ejemplo, el de GitHub.

Estas columnas de “tormenta de ideas” se pueden usar, por ejemplo, 
para elaborar colaborativamente una épica. De esa épica, 
posteriormente, surgirán las diferentes historias de usuario. 
Pero eso lo veremos a continuación.

Respetando los deseos de los clientes de forma incremental: milestones
Como la metodología ágil aboga por presentar frecuentemente 
los resultados al cliente para ver si corresponde a sus 
expectativas, y cambiar o adaptar los requerimientos como 
resultados de las mismas, por lo que el desarrollo de un 
producto se debe hacer de forma incremental como una serie 
de entregables, cada uno de ellos apoyado en el anterior, 
con complejidad creciente y también un acercamiento creciente 
al cumplimiento de las historias de usuario, las cuales, en muchos 
casos, no se podrán cumplir hasta el producto final.

Todo el desarrollo tiene que organizarse alrededor de estos 
entregables o milestones. La metáfora es que uno va avanzando 
por la carretera, hasta llegar al destino final, que es un 
producto que satisface una cantidad aceptable de historias 
de usuario y puede, por tanto, ser desplegado o subido a un 
app store o simplemente una versión nueva en una biblioteca.

Los milestones, por tanto, tienen que cumplir estas características

Tiene que estar ordenados en una progresión lógica, que incluya 
todas las etapas del desarrollo, o al menos todas las que terminen 
en código en el repositorio.
Cada milestone tiene que describir un producto mínimamente viable. 
El producto mínimamente viable tiene que ser más complejo que 
el anterior, incluirlo y agrupar todo el desarrollo hecho desde 
el entregable anterior.
Que sea mínimamente significa que sólo va a incluir lo 
estrictamente necesario para que funcione; y que sea viable 
indica que tiene que ser un producto real, con un criterio 
de aceptación, y no una simple agrupación de tareas no 
relacionadas entre sí. Estos tests, casi siempre, estarán 
automatizados, aunque en la realidad la viabilidad tendría 
que decidirla el equipo de producto en contacto con los clientes.
También tiene que ser un producto en el sentido que sea algo 
con entidad propia, desde el diseño de una clase con código 
que compile hasta una aplicación cliente-servidor completa 
publicada en un store para las mismas.
Como siempre se va a desarrollar para el siguiente PMV, 
todo desarrollo que se haga tendrá que fluir desde las 
historias de usuario, pasando por issues que lo desarrollen, 
hasta los productos mínimamente viables, que también incluirán 
a los pull requests que agrupen una serie de issues. Las 
historias de usuario, en general, podrán irse moviendo de 
un milestone al siguiente, según se vayan implementando, 
o simplemente dejarse fuera de los milestones; los issues 
siempre tendrán que estar en un milestone. Evidentemente, 
como se va avanzando por una carretera, en general sólo 
se estará trabajando en un PMV.

Por la misma razón, no es necesario planificar desde el 
principio todos los milestones que se vayan a desarrollar, 
sólo una cantidad suficiente para tener claro el horizonte 
al que se avanza; según se vaya desarrollando, se verá la 
necesidad de crear nuevos milestones, con releases que 
pueden ser internas, para el propio equipo, o externas, para el cliente.

Los PMVs pueden ser internos o externos. En general, 
son un punto de control para pararse y decir 
“¿Es esto lo que queremos/quiere el cliente?”. 
También es una forma tangible del desarrollo, puesto 
que es algo que se puede liberar o publicar. 
Por eso también se suele establecer un tag para 
el repositorio con cada uno de los PMVs, que 
establezcan claramente cuál era el punto en el 
desarrollo. A ese punto se puede volver, por ejemplo, 
para corregir errores o simplemente volver a él si algún 
PMV posterior no es viable.

1. Motivación/problema que queréis resolver. ¿Por qué queréis 
hacer este TFG? ¿A quién ayuda? ¿Quién lo usaría? 
¿Qué solución proponéis? La ingeniería del software 
trata de resolver problemas, no de hacer aplicaciones, 
y los problemas deben estar antes que nada.
2. De la motivación saldrán los objetivos que os planteáis 
y de los objetivos una serie de productos mínimamente viables, claro. 
Recordad mi artículo sobre cómo formular objetivos que os lo 
he puesto miles de veces.

Buenas. Parece que algunos estáis poniéndoos más en serio con el TF, 
así que unos cuantos consejos.
1. Tratad de usar el desarrollo ágil tanto para la parte más de 
rollete o la matemática como para la parte más de desarrollo. 
Lo que viene a continuación viene de ahí.
2. Plantead una serie de milestones/PMVs de forma que en cada 
parte del camino tengáis algo que entregar, y también 
la documentación correspondiente. Plantead plazos razonables para los mismos.
3. En muchos casos tendréis que plantear historias de 
usuario; en general, sirven siempre porque te centran 
en los problemas que quieres solucionar y los objetivos 
que quieres alcanzar. Las historias de usuario están 
relacionadas con la lógica de negocio de vuestro proyecto 
y tenéis que tener claro cuál es esta y siempre son un 
beneficio para el usuario o los posibles usuarios del proyecto
4. Los issues siempre plantean un problema. Siempre están 
enmarcados en un milestone, y siempre tienen que tener un 
criterio de aceptación para ser cerrados. 
5. Intentad que todo el código se incorpore mediante PRs, 
y dejad los PRs un tiempo para darme tiempo a mi y al cotutor en su caso 
a comentar. Si veis uno especialmente complicado, pasadlo 
también por aquí que los anteriores trabajofindecarrerantes 
y los de esta hornada igual os podrán echar una mano.

la secuencia sería:
Objetivos del TFG - Milestones - Issues que vayan desarrollando los PMVs - 
PRs que vayan avanzando esos issues y cerrando.

Recordad que siempre la secuencia es objetivos - personas o clientes -
 historias de usuario - milestones - a programar.

También recordatorio de los 2-3 primeros milestones:
Milestone 0: Repo configurado con corrección ortográfica, 
memoria comenzada con objetivos y motivación, metodología, es decir, 
todo esto de los milestones, ágil, DDD, explicado. 
También configuración global, gestor de tareas- makefile o lo que uséis, 
etcétera.
Milestone 1: Identificación de las estructuras de datos 
fundamentales y de los elementos principales de la 
lógica de negocio, y programación de los mismos. 
Este PMV será una biblioteca con mínima funcionalidad 
y todos los tests pasando. En los proyectos más de 
investigación, alternativamente sería crear el capítulo 
del estado del arte.Y este sería el posterior. Estos dos 
son milestones internos
Milestone 2: A partir de aquí ya empezaréis a hacer la 
aplicación externa: API, cliente Telegram, alimentación 
de la librería, descarga de datos reales, lo que sea. 
Será un poco más específico de vuestro  TFG.

Una regla del pulgar para las historias de usuario: Siempre 
tienen que expresar un deseo y un beneficio para el usuario. 
Si pones "ojalá qué" y te lo imaginas en la boca del usuario 
y suena creíble, es que es una historia de usuario. Si no, pues no.
"Ojalá que pueda iniciar sesión y registrarme" ¿Suena creíble? ¿No? 
Pues no es una historia de usuario, es un issue o tarea que 
tú necesitas que el usuario haga para que cumpla sus deseos.

Os recuerdo que parte integral del TFG es saber organizar 
bien el desarrollo del mismo. Y esto no solamente por el tribunal, 
sino simplemente por vuestra salud mental y física, y para 
optimizar la experiencia de aprendizaje que es lo que es un 
TFG. El objetivo del TFG no es hacer el TFG, sino aprender 
a gestionar un proyecto siguiendo las mejores prácticas.

La memoria suele empezar con los objetivos, tras un breve paso 
por la motivación/problema; no siempre es así, pero 
así debería ser. El primer capítulo debe empezar por 
la motivación: “Por razones legales, en una serie de locales 
se necesita saber en tiempo real cuantas personas se encuentran 
en el mismo, así como tener un histórico” y el planteamiento 
del problema: “Se necesita un sistema de medición automática 
del aforo y de la duración de la estancia de una persona 
en un recinto cerrado”, pero a continuación, se deben 
experesar cuales son los objetivos del trabajo, es decir, 
qué parte de ese problema vamos a dejar resuelta y cuál 
se va a dejar como trabajo futuro.

Construir un sistema tal como el que a priori se va a necesitar- que 
iremos concretando durante el trabajo- implica ver qué componentes, 
partes o productos mínimamente viables van a ser necesarios 
durante su desarrollo; también ver cuales son los casos de uso 
reales. Por ejemplo, puede que sea un sólo local en cuyo caso 
la solución será relativamente fácil: algo que se ejecute en 
un dispositivo en el mismo local. Pero puede ser un local 
con muchas estancias; o pueden ser muchos locales separados 
físicamente. Los objetivos deben estar claros, porque de 
los objetivos saldrán los casos de uso -una vez más, los casos 
de uso son muy importantes- y de los casos de uso los 
hitos y tareas para resolverlos. Por ejemplo, puede ser 
el siguiente objetivo.

Crear un sistema que se pueda conectar a un sistema informático 
existente y que sea capaz de contar el número total de 
personas en un local así como tiempo de permanencia, 
con el sistema costando menos de 30€ en total.
Los objetivos deben ser alcanzables, y en lo posible 
cuantitativos. En este caso, nos hemos comprometido 
a que valga menos de 30€ -lo que puede excluir, por ejemplo, 
equipos del tipo Raspi-. Pero en subobjetivos se puede ir más allá.

Subobjetivos
Debe ser capaz de contar en recintos de x metros cuadrados.
Debe contar el número de personas con una resolución de 5 minutos.
En el primer caso, va a ser totalmente diferente la solución 
dependiendo de la dimensión del recinto; el segundo nos va a 
dar un límite en la capacidad de procesamiento del sistema. 
Que en este caso es amplia, pero puede ser de 1 segundo, en 
cuyo caso habrá que componérselas.

No será un objetivo, por ejemplo

Construir un dispositivo basado en una Raspberry Pi que 
capte WiFi y Bluetooth
Por varias razones. Un objetivo siempre tiene que estar 
en el dominio del problema, o en un contexto de negocio. 
Si el problema, por ejemplo, es automatizar los procesos 
de desarrollo de una empresa que provee soluciones de 
gestión de contenidos, un objetivo podrá ser “Crear 
configuraciones repetibles que funcionen con una sola 
orden” o “reducir el tiempo de despliegue de desarrollo 
a 5 minutos” o “Poder adaptar soluciones existentes a 
una nueva solución con una semana-persona”. El objetivo no será nunca

Desarrollar un script de ansible que instale todas las 
aplicaciones que usamos ahora.
Un objetivo nunca debe formularse como una solución 
específica a un problema; es algo que se debe de 
alcanzar, y justificar, durante el desarrollo de 
un proyecto. Y nunca debe ser una tarea cerrada. 
Un TF siempre debe resolver un problema,o parte del mismo, no hacer una tarea.

\section{Clientes}
A su vez, dentro del análisis de fútbol, podemos destacar los siguientes roles:

\begin{itemize}
    \item Analista táctico: se encarga de estudiar los equipos y cómo 
    se desenvuelven en los diferentes partidos. Querrá obtener un análisis 
    del propio equipo y de los rivales.
    \item Scouter: es la persona encargada de la búsqueda y captación 
    de jugadores. Querrá encontrar los jugadores que necesita el equipo 
    o el club, por lo que analiza sus cualidades y posibilidades de 
    integración al equipo, desde su rendimiento futbolístico hasta el 
    económico.
    \item Analista de datos: toma la información estadística de 
    cada partido tanto en lo individual como en lo colectivo. 
    Establece relaciones para encontrar respuestas o ideas que 
    puedan colaborar con la toma de decisiones del club referentes 
    a lo táctico, lo técnico y lo económico, para el modelo de 
    juego del equipo o para la compra y venta de jugadores. Por ejemplo: del 
    equipo femenino de Noruega. 
    \item Persona que apuesta: querrá inferir el resultado de un partido, 
    quién marcará y así, una vez se publiquen los jugadores. 
    \item Entrenador: querrá saber a quién sacar durante un partido, los 
    cambios, dónde poner a quién. Por ejemplo: entrenadora principal y 
    segunda entrenadora del Club de Fútbol Internacional del Granada.
    \item Matemático ?
    \item Informático ?
    \item Aficionado  ?
\end{itemize}

Manteniendo esto en mente, nuestra solución 
podría ser usada por ellos. Vemos entonces 
que el trabajo se puede enfocar de diversas 
maneras, y conforme avancemos habremos de descartar algunas y 
quedarnos con otras, quedando todo debidamente justificado. Dependerá de los 
datos que se encuentren disponibles, y la necesidad que haya en el mercado. 
Normalmente y si consultamos la literatura, los análisis son estáticos; 
rendimiento y mapas de calor de un jugador, desde dónde se ha lanzado más 
a portería, etc. pero no hay tanto estudiado en cuanto a causalidad.

% PERSONALIZAR 

\section{Historias de usuario}  


