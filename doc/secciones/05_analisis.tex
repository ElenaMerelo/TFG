\chapter{Desarrollo teórico}
En este capítulo estableceremos la base matemática del proyecto. Principalmente nos basaremos en 
los libros \textit{Análisis de datos avanzado desde un punto de vista elemental} \cite{ada}, 
\textit{Learning Bayesian Networks} \cite{neapolitan} 
y \textit{Redes probabilísticas para aficionados - Una guía para la construcción y análisis de redes 
bayesianas y diagramas de influencia} \cite{pgm}, junto con el capítulo 
\textit{Visión general de la representación y descubrimiento de relaciones causales usando redes 
bayesianas} \cite{cooper} y la tesis \textit{Modelos de clasificación de documentos basados en redes 
bayesianas} \cite{tesis-alfonso}.

\section{Teoría de la probabilidad}

\subsection{Conceptos básicos}
En esta subsección revisaremos algunos conceptos de teoría de la probabilidad básicos, en el 
caso discreto. 

\subsubsection{Funciones y espacios de probabilidad}
Un {\em espacio muestral} es un conjunto contable\footnote{Un conjunto es {\em contable} si tiene el mismo número de 
elementos (cardinalidad) que algún subconjunto de los números naturales, $\mathbb{N}$.} $\Omega = \{x_1, x_2, 
\dots \}$ que representa los posibles resultados de un experimento.

Una función $P : 2^\Omega \longrightarrow \mathbb{R}$, donde $2^\Omega$ es el conjunto de todos los 
subconjuntos (eventos) de $\Omega$, se denomina {\em función de probabilidad} si satisface los axiomas de 
probabilidad de Kolmogorov:

\begin{enumerate}
    \item $0 \leq P(A) \leq 1, \forall A  \subseteq \Omega$.
    \item $P(\Omega) = 1$.
    \item Si $E_1, E_2, \dots$ son tales que $E_i \cap E_j = \emptyset, \quad \forall i\neq j$, entonces
    $$P\left(\cup_i E_i\right) = \sum_i P(E_i).$$
\end{enumerate}

Si $P$ es una función probabilística, el par $(\Omega, P)$ se llama {\em espacio de probabilidad}.

\subsubsection{Probabilidad condicionada y teorema de Bayes}\label{condi}

Sean $A, B \subseteq \Omega$ tales que $P(B) \neq 0$. Entonces, la {\em probabilidad condicionada} de $A$, 
dado $B$ y notada como $P(A|B)$ viene dada por:

$$P(A|B) = \frac{P(A \cap B)}{P(B)}.$$

Diremos que dos eventos $A,B$, donde $P(A) \neq 0$ y $P(B) \neq 0$ son {\em independientes} si $P(A|B) = P(A)$, 
y son {\em condicionalmente independientes} si dado $C$, $P(A|B \cap C) = P(A|C)$.

Si $E_1, \dots, E_n$ es un conjunto de eventos mutuamente disjuntos tales que $\cup_i E_i = \Omega$, esto es, 
son una {\em partición} del espacio muestral, y $P(E_i) > 0, \forall i = 1, \dots, n$, entonces para cualquier 
evento $A$: 

\begin{equation}
P(A) = \sum_{i=1}^n P(A \cup E_i) = \sum_{i=1}^n P(A|E_i)P(E_i). 
\label{lawoftotalprobability}
\end{equation}

Esta propiedad se llama {\em regla de probabilidad total}, y puede ser demostrada con teoría básica de conjuntos.

%\begin{theorem} \emph{(Bayes)} 
%Dados dos eventos $A, B \in \Omega$, tales que $P(A) \neq 0$ y $P(B) \neq 0$, tenemos que
%$$P(A|B) = \frac{P(A)P(B|A)}{P(B)}.$$
%\end{theorem}

%\begin{proof}
%Using the definition of conditional probability, $P(A|B) = \frac{P(A \cap B)}{P(B)}$ and $P(B|A) = \frac{P(A \cap B)}{P(A)}$.
%Therefore $P(A|B)P(B) = P(B|A)P(A)$.--
%\end{proof}

\subsubsection{Variables aleatorias}

Una {\em variable aleatoria} (discreta) es una función que mapea eventos a valores de un conjunto contable, donde 
cada valor tiene una probabilidad mayor o igual a cero. Representaremos las variables aleatorias con letras 
mayúsculas, y los valores a los que los eventos son mapeados, con mínusculas. 

Una variable aleatoria induce una nueva función de probabilidad sobre sus valores. Usaremos la notación $X=x$ para 
representar el conjunto de eventos de $\Omega$ mapeados por $X$ a $x$. Si definimos $P_X(\{x\}) := P(X=x)$, 
entonces $P_X$ es una función de probabilidad. De ahora en adelante escribiremos simplemente $P(X=x)$, que se 
denominará la {\em distribución de probabilidad} de $X$ (o solo {\em distribución} de $X$). Si sabemos que $X$ 
es una variable aleatoria, podemos denotar su distribución como $P(X)$ sin ambigüedad.

En ocasiones, dada una variable aleatoria $X$ y siendo $x$ uno de sus valores, escribiremos para ser más breves 
$p(x)$ en vez de $P(X=x)$. Esta cantidad es la {\em probabilidad de $x$}.

Asimismo, para una variable aleatoria $A$, denominaremos al conjunto de valores que $A$ puede tener como 
``rango de $A$'', $\Omega_A$.

Dadas $X,Y$ variables aleatorias definidas en el mismo espacio muestral, y dos valores $x$ de $X$ e $y$ de 
$Y$, podemos medir la probabilidad del evento intersección $P(X=x, Y=y)$, la cual se denomina {\em distribución 
de probabilidad conjunta} de $X$ e $Y$. Podemos definir la distribución de probabilidad conjunta de un conjunto 
arbitrario de variables aleatorias $\{X_1, X_2, \dots, X_n \}$ como $P(X_1=x_1, X_2=x_2,\dots, X_n=x_n )$.

Pasamos a introducir la operación conocida como {\em marginalización}. Dada una distribución de probabilidad 
conjunta $P(X=x,Y=y)$, podemos obtener la distribución $P(X=x)$ (llamada {\em distribución marginal de 
probabilidad de $X$}\footnote{El término ``marginal'' se usa cuando una distribución se obtiene por marginalización 
de otra distribución conjunta, pero de hecho es también una distribución ``convencional''.}), sumando sobre todos 
los valores de $y$ en el rango de $Y$: 

$$P(X=x) = \sum_y P(X=x, Y=y).$$

Esta es otra expresión de la ley de probabilidad total \ref{lawoftotalprobability}.

En último lugar, una vez entendida la analogía entre variable aleatoria y eventos, podemos definir la 
{\em distribución de probabilidad condicionada} de una variable aleatoria $X$ dado $Y$:

$$P(X=x|Y=y) = \frac{P(X=x, Y=y)}{P(Y=y)}.$$

Este caso se puede extender a un conjunto de dos o más variables. Un resultado que permite calcular la 
distribución conjunta de un conjunto de variables aleatorias usando únicamente probabilidades condicionadas 
es la {\em regla de la cadena}:

$$P(X_1=x_1, \dots, X_n=x_n) = \prod_{i=1}^n P(X_i=x_i|X_{i-1}=x_{i-1}, \dots, X_1=x_1),$$ la cual puede 
probarse fácilmente como aplicación directa del teorema de Bayes \ref{eq:bayes}.

\subsubsection{Independencia condicionada y observaciones de variables aleatorias}

Dos de las nociones ``clásicas'' en teoría de la probabilidad (y ya mencionadas en la sección \ref{condi}) son 
el concepto de {\em independencia} y {\em independencia condicionada}. 

Desde el punto de vista de variables aleatorias, podemos reescribir la definición de {\em eventos independientes}; 
diremos que dos eventos $X=x$ e $Y=y$ (siendo $x,y$ dos valores de las variables aleatorias $X,Y$) son 
independientes si 

$$p(x,y) = p(x) \, p(y).$$

Además, $X$ e $Y$ son {\em independientes} sí y solo sí $$P(X=x, Y=y) = P(X=x) \, P(Y=y),$$ 
para todos los valores $x,y$ de $X$ e $Y$, respectivamente.

Para problemas con al menos tres variables aleatorias, $X,Y,Z$, puede observarse {\em independencia 
condicionada}; diremos que, dada $Z$, $X$ e $Y$ son {\em independientes condicionadamente } $\leftrightarrow$ todo par 
de valores $x$ (de $X$) e $y$ (de $Y$) es independiente condicionadamente para cada $z$ (de $Z$), tal que 
$p(z) > 0$, esto es:

$$\forall x, y, z, \quad p(z) > 0 \,\, \Rightarrow \,\, p(x,y|z) = p(x|z)\, p(y|z).$$

Este concepto no está solo limitado a tres variables, y se puede extender a conjuntos grandes.

Diremos que una variable es {\em observada} si toma uno de los valores de su rango. Si queremos testear la {\em 
independencia con respecto a una variable observada}, necesitamos únicamente testear la independencia con respecto 
a ese valor asignado. Es de notar que observar una variable puede cambiar las relaciones de independencia entre
un conjunto de variables.

%wip 
