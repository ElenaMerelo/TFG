\chapter{Desarrollo teórico}
En este capítulo estableceremos la base matemática del proyecto. Principalmente nos basaremos en 
los libros \textit{Análisis de datos avanzado desde un punto de vista elemental} \cite{ada}, 
\textit{Learning Bayesian Networks} \cite{neapolitan} 
y \textit{Redes probabilísticas para aficionados - Una guía para la construcción y análisis de redes 
bayesianas y diagramas de influencia} \cite{pgm}, junto con el capítulo 
\textit{Visión general de la representación y descubrimiento de relaciones causales usando redes 
bayesianas} \cite{cooper} y la tesis \textit{Modelos de clasificación de documentos basados en redes 
bayesianas} \cite{tesis-alfonso}.

\section{Teoría de la probabilidad}

\subsection{Conceptos básicos}
En esta subsección revisaremos algunos conceptos de teoría de la probabilidad básicos, en el 
caso discreto. 

\subsubsection{Funciones y espacios de probabilidad}
Un {\em espacio muestral} es un conjunto contable\footnote{Un conjunto es {\em contable} si tiene el mismo número de 
elementos (cardinalidad) que algún subconjunto de los números naturales, $\mathbb{N}$.} $\Omega = \{x_1, x_2, 
\dots \}$ que representa los posibles resultados de un experimento.

Una función $P : 2^\Omega \longrightarrow \mathbb{R}$, donde $2^\Omega$ es el conjunto de todos los 
subconjuntos (eventos) de $\Omega$, se denomina {\em función de probabilidad} si satisface los axiomas de 
probabilidad de Kolmogorov:

\begin{enumerate}
    \item $0 \leq P(A) \leq 1, \forall A  \subseteq \Omega$.
    \item $P(\Omega) = 1$.
    \item Si $E_1, E_2, \dots$ son tales que $E_i \cap E_j = \emptyset, \quad \forall i\neq j$, entonces
    $$P\left(\cup_i E_i\right) = \sum_i P(E_i).$$
\end{enumerate}

Si $P$ es una función probabilística, el par $(\Omega, P)$ se llama {\em espacio de probabilidad}.

\subsubsection{Probabilidad condicionada y teorema de Bayes}\label{condi}

Sean $A, B \subseteq \Omega$ tales que $P(B) \neq 0$. Entonces, la {\em probabilidad condicionada} de $A$, 
dado $B$ y notada como $P(A|B)$ viene dada por:

$$P(A|B) = \frac{P(A \cap B)}{P(B)}.$$

Diremos que dos eventos $A,B$, donde $P(A) \neq 0$ y $P(B) \neq 0$ son {\em independientes} si $P(A|B) = P(A)$, 
y son {\em condicionalmente independientes} si dado $C$, $P(A|B \cap C) = P(A|C)$.

Si $E_1, \dots, E_n$ es un conjunto de eventos mutuamente disjuntos tales que $\cup_i E_i = \Omega$, esto es, 
son una {\em partición} del espacio muestral, y $P(E_i) > 0, \forall i = 1, \dots, n$, entonces para cualquier 
evento $A$: 

\begin{equation}
P(A) = \sum_{i=1}^n P(A \cup E_i) = \sum_{i=1}^n P(A|E_i)P(E_i). 
\label{lawoftotalprobability}
\end{equation}

Esta propiedad se llama {\em regla de probabilidad total}, y puede ser demostrada con teoría básica de conjuntos.

%\begin{theorem} \emph{(Bayes)} 
%Dados dos eventos $A, B \in \Omega$, tales que $P(A) \neq 0$ y $P(B) \neq 0$, tenemos que
%$$P(A|B) = \frac{P(A)P(B|A)}{P(B)}.$$
%\end{theorem}

%\begin{proof}
%Using the definition of conditional probability, $P(A|B) = \frac{P(A \cap B)}{P(B)}$ and $P(B|A) = \frac{P(A \cap B)}{P(A)}$.
%Therefore $P(A|B)P(B) = P(B|A)P(A)$.--
%\end{proof}

\subsubsection{Variables aleatorias}

Una {\em variable aleatoria} (discreta) es una función que mapea eventos a valores de un conjunto contable, donde 
cada valor tiene una probabilidad mayor o igual a cero. Representaremos las variables aleatorias con letras 
mayúsculas, y los valores a los que los eventos son mapeados, con mínusculas. 

Una variable aleatoria induce una nueva función de probabilidad sobre sus valores. Usaremos la notación $X=x$ para 
representar el conjunto de eventos de $\Omega$ mapeados por $X$ a $x$. Si definimos $P_X(\{x\}) := P(X=x)$, 
entonces $P_X$ es una función de probabilidad. De ahora en adelante escribiremos simplemente $P(X=x)$, que se 
denominará la {\em distribución de probabilidad} de $X$ (o solo {\em distribución} de $X$). Si sabemos que $X$ 
es una variable aleatoria, podemos denotar su distribución como $P(X)$ sin ambigüedad.

En ocasiones, dada una variable aleatoria $X$ y siendo $x$ uno de sus valores, escribiremos para ser más breves 
$p(x)$ en vez de $P(X=x)$. Esta cantidad es la {\em probabilidad de $x$}.

Asimismo, para una variable aleatoria $A$, denominaremos al conjunto de valores que $A$ puede tener como 
``rango de $A$'', $\Omega_A$.

Dadas $X,Y$ variables aleatorias definidas en el mismo espacio muestral, y dos valores $x$ de $X$ e $y$ de 
$Y$, podemos medir la probabilidad del evento intersección $P(X=x, Y=y)$, la cual se denomina {\em distribución 
de probabilidad conjunta} de $X$ e $Y$. Podemos definir la distribución de probabilidad conjunta de un conjunto 
arbitrario de variables aleatorias $\{X_1, X_2, \dots, X_n \}$ como $P(X_1=x_1, X_2=x_2,\dots, X_n=x_n )$.

Pasamos a introducir la operación conocida como {\em marginalización}. Dada una distribución de probabilidad 
conjunta $P(X=x,Y=y)$, podemos obtener la distribución $P(X=x)$ (llamada {\em distribución marginal de 
probabilidad de $X$}\footnote{El término ``marginal'' se usa cuando una distribución se obtiene por marginalización 
de otra distribución conjunta, pero de hecho es también una distribución ``convencional''.}), sumando sobre todos 
los valores de $y$ en el rango de $Y$: 

$$P(X=x) = \sum_y P(X=x, Y=y).$$

Esta es otra expresión de la ley de probabilidad total \ref{lawoftotalprobability}.

En último lugar, una vez entendida la analogía entre variable aleatoria y eventos, podemos definir la 
{\em distribución de probabilidad condicionada} de una variable aleatoria $X$ dado $Y$:

$$P(X=x|Y=y) = \frac{P(X=x, Y=y)}{P(Y=y)}.$$

Este caso se puede extender a un conjunto de dos o más variables. Un resultado que permite calcular la 
distribución conjunta de un conjunto de variables aleatorias usando únicamente probabilidades condicionadas 
es la {\em regla de la cadena}:

$$P(X_1=x_1, \dots, X_n=x_n) = \prod_{i=1}^n P(X_i=x_i|X_{i-1}=x_{i-1}, \dots, X_1=x_1),$$ la cual puede 
probarse fácilmente como aplicación directa del teorema de Bayes \ref{eq:bayes}.

\subsubsection{Independencia condicionada y observaciones de variables aleatorias}

Dos de las nociones ``clásicas'' en teoría de la probabilidad (y ya mencionadas en la sección \ref{condi}) son 
el concepto de {\em independencia} y {\em independencia condicionada}. 

Desde el punto de vista de variables aleatorias, podemos reescribir la definición de {\em eventos independientes}; 
diremos que dos eventos $X=x$ e $Y=y$ (siendo $x,y$ dos valores de las variables aleatorias $X,Y$) son 
independientes si 

$$p(x,y) = p(x) \, p(y).$$

Además, $X$ e $Y$ son {\em independientes} sí y solo sí $$P(X=x, Y=y) = P(X=x) \, P(Y=y),$$ 
para todos los valores $x,y$ de $X$ e $Y$, respectivamente.

Para problemas con al menos tres variables aleatorias, $X,Y,Z$, puede observarse {\em independencia 
condicionada}; diremos que, dada $Z$, $X$ e $Y$ son {\em independientes condicionadamente } $\leftrightarrow$ todo par 
de valores $x$ (de $X$) e $y$ (de $Y$) es independiente condicionadamente para cada $z$ (de $Z$), tal que 
$p(z) > 0$, esto es:

$$\forall x, y, z, \quad p(z) > 0 \,\, \Rightarrow \,\, p(x,y|z) = p(x|z)\, p(y|z).$$

Este concepto no está solo limitado a tres variables, y se puede extender a conjuntos grandes.

Diremos que una variable es {\em observada} si toma uno de los valores de su rango. Si queremos testear la {\em 
independencia con respecto a una variable observada}, necesitamos únicamente testear la independencia con respecto 
a ese valor asignado. Es de notar que observar una variable puede cambiar las relaciones de independencia entre
un conjunto de variables.

Escribiremos $A\perp B | C$ cuando una variable $A$ es independiente de otra, $B$, tras la observación de $C$. Si 
$A$ es independiente de $B$, sin observaciones adicionales, escribiremos $A \perp B$.

Dados $\mathbf{W, X, Y, Z}$ conjuntos de variables aleatorias, las relaciones de independencia tienen 
las siguientes propiedades:

\begin{itemize}
 \item Simetría $(\mathbf{X} \perp \mathbf{Y} | \mathbf{Z}) \Rightarrow (\mathbf{Y} \perp \mathbf{X} | \mathbf{Z})$.
 \item Descomposición $(\mathbf{X} \perp \mathbf{Y, W} | \mathbf{Z}) \Rightarrow (\mathbf{X} \perp \mathbf{Y} | \mathbf{Z})$.
\end{itemize}

\section{Redes bayesianas}

Las redes bayesianas nos ayudan a modelar y entender las muchas variables que informan nuestro proceso de 
toma de decisiones. Las decisiones más complejas están normalmente basadas en una multitud de factores o 
variables. Por ejemplo, para el presidente de un equipo de fútbol \ref{hu:presidente}, podemos 
mapear la decisión que tiene que tomar y las diferentes variables usando 
una red bayesiana, esto es, un modelo gráfico que captura la relación entre variables que están bajo 
supuestos de causalidad o influencia \cite{things-to-know-BN}.

Como ya hemos comentado en \ref{subsect:BN}, \textbf{una red bayesiana es un diagrama que 
usa flechas o arcos dirigidos para mostrar cómo distintos factores, representados por nodos elípticos, se 
influencian los unos a los otros.} Cada nodo viene con una tabla de probabilidades condicionadas, la cual 
refleja las posibilidades de que tenga lugar distintos desenlaces, provenientes de las influencias que 
le afectan directamente. Una vez la estructura del grafo y dicha tabla han sido definidas, hay algoritmos 
estándar que calculan los estados de las variables desconocidas basándose en los estados de las variables 
conocidas en el modelo \cite{learning-algorithms-BN-comparison}, \cite{BN-achilles-heel}, 
\cite{different-algorithmic-schemes}.

Una de las razones por las que las redes bayesianas son tan potentes es que pueden realizar inferencias 
tanto predictivas como diagnósticas. Por ejemplo, podemos por un lado predecir la posición en la liga de 
un equipo para un valor dado de rendimiento, y por otro ingresar un estado de posición en la 
liga como observación para examinar qué nivel de desempeño del equipo podría explicarla. Estos algoritmos 
estándar son llamados algoritmos de ``propagación bayesiana" \cite{Cano2004}, \cite{more-algorithms}, 
\cite{back-prop} porque se basan en el teorema de Bayes; en ellos, la probabilidad de una variable 
desconocida se actualiza después de que se obtenga evidencia relevante para esa variable \cite{prop-alg}.

\begin{theorem}\emph{(Factorización de una red bayesiana)} 
La distribución conjunta de una red bayesiana $P(X_1, \dots, X_n)$ se factoriza de la siguiente manera:

$$P(X_1, \dots, X_n) = \prod_{i=1}^n P(X_i|pa(X_i))$$

donde $pa(X_i)$ es el conjunto de padres de la variable en el grafo. 
\end{theorem}

